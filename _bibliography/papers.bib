---
---

@string{CVPR = {CVPR}}
@string{ICLR = {ICLR}}
@string{ICCV = {ICCV}}
@string{WACV = {WACV}}
@string{NeurIPS = {NeurIPS}}





@inproceedings{abs-2108-07884,
 abbr={WACV},
  author    = {Ali Dabouei and
               Sobhan Soleymani and
               Jeremy Dawson and
               Nasser M. Nasrabadi},
  title     = {Fast Geometrically-Perturbed Adversarial Faces},
  booktitle = WACV,
  year      = {2019},
  arxiv       = {1809.08999},
  abstract = {The state-of-the-art performance of deep learning algorithms has led to a considerable increase in the utilization of machine learning in security-sensitive and critical applications. However, it has recently been shown that a small and carefully crafted perturbation in the input space can completely fool a deep model. In this study, we explore the extent to which face recognition systems are vulnerable to geometrically-perturbed adversarial faces. We propose a fast landmark manipulation method for generating adversarial faces, which is approximately 200 times faster than the previous geometric attacks and obtains 99.86% success rate on the state-of-the-art face recognition models. To further force the generated samples to be natural, we introduce a second attack constrained on the semantic structure of the face which has the half speed of the first attack with the success rate of 99.96%. Both attacks are extremely robust against the state-of-the-art defense methods with the success rate of equal or greater than 53.59%.},
        selected={true}
}

@inproceedings{abs-2108-07884,
 abbr={WACV},
  author    = {Ali Dabouei and
               Sobhan Soleymani and
               Jeremy Dawson and
               Nasser M. Nasrabadi},
  title     = {Fast Geometrically-Perturbed Adversarial Faces},
  booktitle = WACV,
  year      = {2019},
  arxiv       = {1809.08999},
  code     = {https://github.com/alldbi/FLM}
  abstract = {The state-of-the-art performance of deep learning algorithms has led to a considerable increase in the utilization of machine learning in security-sensitive and critical applications. However, it has recently been shown that a small and carefully crafted perturbation in the input space can completely fool a deep model. In this study, we explore the extent to which face recognition systems are vulnerable to geometrically-perturbed adversarial faces. We propose a fast landmark manipulation method for generating adversarial faces, which is approximately 200 times faster than the previous geometric attacks and obtains 99.86% success rate on the state-of-the-art face recognition models. To further force the generated samples to be natural, we introduce a second attack constrained on the semantic structure of the face which has the half speed of the first attack with the success rate of 99.96%. Both attacks are extremely robust against the state-of-the-art defense methods with the success rate of equal or greater than 53.59%.},
        selected={true}
}